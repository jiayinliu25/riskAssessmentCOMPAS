{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.85      0.91      0.88      2603\\n           1       0.74      0.60      0.66      1056\\n\\n    accuracy                           0.82      3659\\n   macro avg       0.79      0.76      0.77      3659\\nweighted avg       0.82      0.82      0.82      3659\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "compas = pd.read_csv('./data/compas.csv')\n",
    "\n",
    "\n",
    "compas['reoffend'] = compas['v_decile_score'].apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "# Selecting features and target\n",
    "features = compas[['age', 'priors_count']]\n",
    "target = compas['reoffend']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(train_features, train_target)\n",
    "\n",
    "# Making predictions\n",
    "predicted_classes = model.predict(test_features)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(test_target, predicted_classes)\n",
    "report = classification_report(test_target, predicted_classes)\n",
    "conf_matrix = confusion_matrix(test_target, predicted_classes)\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Assuming 'compas' is your dataset\n",
    "\n",
    "# Add a new column for binary reoffend variable\n",
    "compas['reoffend'] = compas['v_decile_score'].apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "# Selecting features and target for the old model\n",
    "features_old = compas[['age', 'priors_count']]\n",
    "target_old = compas['reoffend']\n",
    "\n",
    "# Splitting the data into training and testing sets for the old model\n",
    "train_features_old, test_features_old, train_target_old, test_target_old = train_test_split(features_old, target_old, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the old logistic regression model\n",
    "model_old = LogisticRegression()\n",
    "model_old.fit(train_features_old, train_target_old)\n",
    "\n",
    "# Making predictions for the old model\n",
    "predicted_classes_old = model_old.predict(test_features_old)\n",
    "\n",
    "# Evaluating the old model\n",
    "accuracy_old = accuracy_score(test_target_old, predicted_classes_old)\n",
    "print(\"Accuracy of the old model:\", accuracy_old)\n",
    "\n",
    "# Selecting features and target for the new model (including 'race')\n",
    "features_new = compas[['age', 'priors_count', 'race']]\n",
    "target_new = compas['reoffend']\n",
    "\n",
    "# Convert categorical variable 'race' into dummy variables\n",
    "features_new = pd.get_dummies(features_new, columns=['race'], drop_first=True)\n",
    "\n",
    "# Splitting the data into training and testing sets for the new model\n",
    "train_features_new, test_features_new, train_target_new, test_target_new = train_test_split(features_new, target_new, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the new linear regression model\n",
    "model_new = LinearRegression()\n",
    "model_new.fit(train_features_new, train_target_new)\n",
    "\n",
    "# Making predictions for the new model\n",
    "predicted_values_new = model_new.predict(test_features_new)\n",
    "\n",
    "# Converting predicted values to binary classes\n",
    "predicted_classes_new = [1 if val > 0.5 else 0 for val in predicted_values_new]\n",
    "\n",
    "# Evaluating the new model\n",
    "accuracy_new = accuracy_score(test_target_new, predicted_classes_new)\n",
    "print(\"Accuracy of the new model:\", accuracy_new)\n",
    "\n",
    "# Comparing the models\n",
    "if accuracy_new > accuracy_old:\n",
    "    print(\"The new model performs better.\")\n",
    "elif accuracy_new < accuracy_old:\n",
    "    print(\"The old model performs better.\")\n",
    "else:\n",
    "    print(\"Both models have the same accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting the classification report for better readability\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Converting the classification report into a dictionary\n",
    "report_dict = classification_report(test_target, predicted_classes, output_dict=True)\n",
    "\n",
    "# Preparing data for tabulation\n",
    "report_data = []\n",
    "for key, value in report_dict.items():\n",
    "    if key == 'accuracy':\n",
    "        report_data.append(['accuracy', '', '', value, report_dict['macro avg']['support']])\n",
    "    elif key in ['macro avg', 'weighted avg']:\n",
    "        report_data.append([key, value['precision'], value['recall'], value['f1-score'], value['support']])\n",
    "    else:\n",
    "        report_data.append([f'Class {key}', value['precision'], value['recall'], value['f1-score'], value['support']])\n",
    "\n",
    "# Creating a table with headers\n",
    "headers = [\"Metric\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
    "table = tabulate(report_data, headers, tablefmt=\"pretty\")\n",
    "\n",
    "# Printing the formatted table\n",
    "print(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [25, 40],\n",
    "    'priors_count': [10, 0]\n",
    "})\n",
    "\n",
    "# Making predictions\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Interpreting predictions\n",
    "prediction_labels = ['Likely to reoffend' if pred == 1 else 'Less likely to reoffend' for pred in predictions]\n",
    "\n",
    "# Display results\n",
    "for i, label in enumerate(prediction_labels):\n",
    "    print(f\"Individual {i+1}: {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
